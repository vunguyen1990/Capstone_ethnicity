{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import linkedinCrawlling_refer\n",
    "import crawling_linkedin\n",
    "try:\n",
    "    from HTMLParser import HTMLParser\n",
    "except ImportError:\n",
    "    from html.parser import HTMLParser\n",
    "import pprint\n",
    "import json\n",
    "import sys\n",
    "import urllib\n",
    "import requests\n",
    "import time\n",
    "import geocoder\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_email = \"nganhvu.gon@gmail.com\"\n",
    "user_password = \"Vunguyen@jvn\"\n",
    "HOMEPAGE_URL = 'https://www.linkedin.com'\n",
    "LOGIN_URL = 'https://www.linkedin.com/uas/login-submit'\n",
    "BASED_ULR = \"https://media.licdn.com/mpr/mpr/shrinknp_400_400\"\n",
    "PHOTO_PATH = \"/photo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linkedin_url = \"http://www.linkedin.com/in/jmkristian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = requests.Session()\n",
    "h = HTMLParser()\n",
    "html = client.get(HOMEPAGE_URL).content\n",
    "soup = BeautifulSoup(html)\n",
    "csrf = soup.find(id=\"loginCsrfParam-login\")['value']\n",
    "\n",
    "login_information = {\n",
    "   'session_key':user_email,\n",
    "   'session_password':user_password,\n",
    "   'loginCsrfParam': csrf,\n",
    "}\n",
    "function_start_time =  time.time()\n",
    "client.post(LOGIN_URL, data=login_information)\n",
    "response_result = client.get(linkedin_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [999]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('request geocode: time', 0.37438082695007324)\n",
      "('request geocode: time', 0.31203603744506836)\n",
      "('request geocode: time', 0.2738511562347412)\n",
      "('userfirstname ', 'Siva', '\\n userlastname', 'Gudavalli')\n",
      "('Company name:', [{'endYear': 2007, 'startMonth': 6, 'name': 'ValueLabs', 'startYear': 2005, 'endMonth': 9}, {'name': 'AIR Worldwide', 'startYear': 2014, 'startMonth': 1, 'endMonth': 3, 'locationName': 'Greater Boston Area', 'endYear': 2015}, {'name': 'Synechron', 'startYear': 2010, 'startMonth': 5, 'endMonth': 1, 'locationName': 'Pune Area, India', 'endYear': 2014}, {'endYear': 2010, 'startMonth': 9, 'name': 'Thomson Reuters', 'startYear': 2007, 'endMonth': 5}, {'locationName': 'Waltham, MA', 'startMonth': 3, 'name': 'Amadeus IT Group', 'startYear': 2015}])\n",
      "('university:', [{'country': u'US', 'endYear': 1999, 'name': \"St.Lukes's Public School\", 'startYear': 1998}, {'country': u'IN', 'endYear': 2001, 'name': 'Vignan Vidyalam', 'startYear': 1999}, {'country': u'IN', 'endYear': 2005, 'name': 'Jawaharlal Nehru Technological University (Anantapur)', 'startYear': 2001}])\n",
      "('language:', [])\n",
      "('All function time spending:', 3.4671168327331543)\n"
     ]
    }
   ],
   "source": [
    "text = response_result.text\n",
    "soup = BeautifulSoup(text, 'html.parser')\n",
    "logfile = open('Log/profile_log_%s.txt' % time.strftime(\"%Y%m%d%H%M\"), 'w')\n",
    "company_list = list()\n",
    "\n",
    "university_list = list()\n",
    "language_list = list()\n",
    "for code in soup.find_all('code'):\n",
    "    code_str = code.get_text()\n",
    "    code_str = h.unescape(code_str)\n",
    "\n",
    "    if 'companyName' in code_str and 'deletedFields' in code_str:\n",
    "        json_data = json.loads(code_str)\n",
    "        dataset = json_data['included']\n",
    "        for data in dataset:\n",
    "            if \"firstName\" in data and 'headline' in data:\n",
    "                pprint.pprint(json_data,logfile)\n",
    "                userfirstname = data[\"firstName\"].encode(\"utf-8\")\n",
    "                userlastname = data[\"lastName\"].encode(\"utf-8\")\n",
    "                print(\"userfirstname \", userfirstname,\"\\n userlastname\",userlastname )\n",
    "            if 'companyName' in data:\n",
    "                company_dict = dict()\n",
    "                company_dict['name'] = data[\"companyName\"].encode(\"utf-8\")\n",
    "                if 'locationName' in data:\n",
    "                    company_dict['locationName'] = data[\"locationName\"].encode(\"utf-8\")\n",
    "                if 'entityUrn' in data:\n",
    "                    company_entityUrn = data['entityUrn'].encode(\"utf-8\")\n",
    "                    for dt in dataset:\n",
    "                        if dt['$type'].encode(\"utf-8\") == 'com.linkedin.common.Date' and dt['$id'].encode(\"utf-8\") == \"%s,timePeriod,startDate\"%company_entityUrn:\n",
    "                            if 'month' in dt:\n",
    "                                company_dict['startMonth'] = dt['month']\n",
    "                            if 'year' in dt:\n",
    "                                company_dict['startYear'] = dt['year']\n",
    "                        if dt['$type'].encode(\"utf-8\") == 'com.linkedin.common.Date' and dt['$id'].encode(\"utf-8\") == \"%s,timePeriod,endDate\"%company_entityUrn:\n",
    "                            if 'month' in dt:\n",
    "                                company_dict['endMonth'] = dt['month']\n",
    "                            if 'year' in dt:\n",
    "                                company_dict['endYear'] = dt['year']\n",
    "                        \n",
    "                company_list.append(company_dict)\n",
    "            if 'schoolName' in data:\n",
    "                pprint.pprint(data,logfile)\n",
    "                university_dict = dict()\n",
    "                university_dict['name'] = data[\"schoolName\"].encode(\"utf-8\")\n",
    "                request_geocoder_start = time.time()\n",
    "                g = geocoder.google(university_dict['name'])\n",
    "                university_dict['country'] = g.country\n",
    "                request_geocoder_end = time.time()\n",
    "                print(\"request geocode: time\", request_geocoder_end - request_geocoder_start)\n",
    "                if 'entityUrn' in data:\n",
    "                    university_entityUrn = data['entityUrn'].encode(\"utf-8\")\n",
    "                    for dt in dataset:\n",
    "                        if dt['$type'].encode(\"utf-8\") == 'com.linkedin.common.Date' and dt['$id'].encode(\"utf-8\") == \"%s,timePeriod,startDate\"%university_entityUrn:\n",
    "                            if 'month' in dt:\n",
    "                                university_dict['startMonth'] = dt['month']\n",
    "                            if 'year' in dt:\n",
    "                                university_dict['startYear'] = dt['year']\n",
    "                        if dt['$type'].encode(\"utf-8\") == 'com.linkedin.common.Date' and dt['$id'].encode(\"utf-8\") == \"%s,timePeriod,endDate\"%university_entityUrn:\n",
    "                            if 'month' in dt:\n",
    "                                university_dict['endMonth'] = dt['month']\n",
    "                            if 'year' in dt:\n",
    "                                university_dict['endYear'] = dt['year']\n",
    "                if 'locationName' in data:\n",
    "                    university_dict['locationName'] = data[\"locationName\"].encode(\"utf-8\")\n",
    "                university_list.append(university_dict)\n",
    "            if 'name' in data and 'proficiency' in data:\n",
    "                language_dict = dict()\n",
    "                language_dict['name'] = data['name'].encode(\"utf-8\")\n",
    "                language_dict['proficiency'] = data['proficiency'].encode(\"utf-8\")\n",
    "                language_list.append(language_dict)\n",
    "            \n",
    "print(\"Company name:\", company_list)\n",
    "print(\"university:\",university_list)\n",
    "print(\"language:\", language_list)\n",
    "function_end_time =  time.time()\n",
    "print(\"All function time spending:\",function_end_time - function_start_time)\n",
    "logfile.close()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
