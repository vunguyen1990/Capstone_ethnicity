{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nativeLang2LangCode(lang):\n",
    "    lang = lang.lower()\n",
    "    json_dir = os.path.join(os.getcwd()+'/json/nativelanguage.json')\n",
    "    # with open(json_dir,encoding='utf-8') as data_file: \n",
    "    new_lang =lang\n",
    "    with open(json_dir) as data_file: \n",
    "        data = json.load(data_file)\n",
    "        for dic in data:\n",
    "            if (data[dic]['name'].lower() == lang) or (data[dic]['nativeName'].lower() == lang):\n",
    "#                 print(data[dic]['name'])\n",
    "                new_lang =  dic\n",
    "    return new_lang\n",
    "nativeLang2LangCode('Hebrew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hispanic/Latino'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def languageCode2ethnicity(languagecode):\n",
    "    file_path = os.path.join(os.getcwd() + '/dictionary/language_continent_dict.csv')\n",
    "#     print(file_path)\n",
    "    language_df = pd.read_csv(file_path)\n",
    "    if languagecode == 'es':\n",
    "        return 'Hispanic/Latino'\n",
    "    else:\n",
    "        continentcode_df = language_df.loc[language_df.name == languagecode]\n",
    "        if continentcode_df.empty:\n",
    "            continentcode = 'UNKNOWN'\n",
    "        else:\n",
    "            continentcode = continentcode_df['dorminant_continent'].values[0]\n",
    "#     print(continentcode)\n",
    "    ethnicity_continent = {'EU':'White/Caucasian', 'SA':'Hispanic/Latino', 'AS':'Asian', 'AF':'Black/African American', 'NA':'White/Caucasian', 'AN':'Other/Multiracial', 'OC':'Other/Multiracial','UNKNOWN':'UNKNOWN'}\n",
    "    ethnicity_continent_notNA = {'EU':'White/Caucasian', 'SA':'Hispanic/Latino', 'AS':'Asian', 'AF':'Black/African American', 'NA':'Other/Multiracial', 'AN':'Other/Multiracial', 'OC':'Other/Multiracial','UNKNOWN':'UNKNOWN'}\n",
    "    return ethnicity_continent_notNA[continentcode]\n",
    "languageCode2ethnicity('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of original data 1000\n",
      "length of lang result data 330\n",
      "length of original data 1000\n",
      "length of lang result data 333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(576, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_data_list = list()\n",
    "lang_data_list = list()\n",
    "join_data_list = list()\n",
    "original_dir = 'Result/original_data'\n",
    "lang_result_dir = 'Result/language_result'\n",
    "original_path = os.path.join(os.getcwd(),original_dir)\n",
    "lang_result_path = os.path.join(os.getcwd(),lang_result_dir)\n",
    "for root, dirs, files in os.walk(original_path):\n",
    "#     print(dirs)\n",
    "    for name in dirs:\n",
    "        #load original file\n",
    "        candidate_sub_list = list()\n",
    "        original_subfolder_path = os.path.join(original_path,name)\n",
    "        for i in range(0,10):\n",
    "            filename = 'sample_data_1000_' + str(i)\n",
    "            candidate_file = filename + '.csv'\n",
    "            candidate_file_path = os.path.join(original_subfolder_path,candidate_file)\n",
    "            candidate_df = pd.read_csv(candidate_file_path)\n",
    "            candidate_sub_list.append(candidate_df)\n",
    "            \n",
    "        candidate_sub_df =  pd.concat(candidate_sub_list)\n",
    "        candidate_sub_df = candidate_sub_df[['candidate_name','candidate_surname','candidate_country','ethnicity','ID','url',\"cand_id\"]]\n",
    "        candidate_sub_df = candidate_sub_df.rename(columns={\"cand_id\": \"candidate_id\"})\n",
    "        candidate_sub_df = candidate_sub_df.rename(columns={\"ID\": \"cand_id\"})\n",
    "        print('length of original data %d'%len(candidate_sub_df))\n",
    "        #load langresult file\n",
    "        lang_sub_list = list()\n",
    "        lang_subfolder_path = os.path.join(lang_result_path,name)\n",
    "        for i in range(0,10):\n",
    "            filename = 'sample_data_1000_%s_language'% str(i)\n",
    "            lang_file = filename + '.csv'\n",
    "            lang_file_path = os.path.join(lang_subfolder_path,lang_file)\n",
    "            lang_df = pd.read_csv(lang_file_path)\n",
    "            lang_sub_list.append(lang_df)\n",
    "            \n",
    "        lang_sub_df =  pd.concat(lang_sub_list)\n",
    "        lang_sub_df = lang_sub_df.loc[lang_sub_df.proficiency == 'NATIVE_OR_BILINGUAL']\n",
    "        lang_sub_df['language_code'] = lang_sub_df.name.apply(lambda row:nativeLang2LangCode(row))\n",
    "        lang_sub_df['Predict_eth'] = lang_sub_df.language_code.apply(lambda row:languageCode2ethnicity(row))\n",
    "        print('length of lang result data %d'%len(lang_sub_df))\n",
    "\n",
    "        #Join data\n",
    "        join_df = pd.merge(lang_sub_df,candidate_sub_df, how= 'left',on=\"cand_id\" )\n",
    "        join_df = join_df[join_df.ethnicity!='Other/Multiracial']\n",
    "        join_df.to_csv('join_df_%s.csv'%name)\n",
    "        join_data_list.append(join_df)\n",
    "join_data_df = pd.concat(join_data_list)\n",
    "join_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load modify file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data_df =pd.read_csv('join_data_df_newModify.csv')\n",
    "len(join_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cand_id</th>\n",
       "      <th>name</th>\n",
       "      <th>proficiency</th>\n",
       "      <th>language_code</th>\n",
       "      <th>Predict_eth</th>\n",
       "      <th>candidate_name</th>\n",
       "      <th>candidate_surname</th>\n",
       "      <th>candidate_country</th>\n",
       "      <th>url</th>\n",
       "      <th>candidate_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cand_id  name  proficiency  language_code  \\\n",
       "ethnicity                                                           \n",
       "Asian                       105   105          105            105   \n",
       "Black/African American       54    54           54             54   \n",
       "Hispanic/Latino             147   147          147            147   \n",
       "White/Caucasian              83    83           83             83   \n",
       "\n",
       "                        Predict_eth  candidate_name  candidate_surname  \\\n",
       "ethnicity                                                                \n",
       "Asian                           105             105                105   \n",
       "Black/African American           54              54                 54   \n",
       "Hispanic/Latino                 147             147                147   \n",
       "White/Caucasian                  83              83                 83   \n",
       "\n",
       "                        candidate_country  url  candidate_id  \n",
       "ethnicity                                                     \n",
       "Asian                                 105  105           105  \n",
       "Black/African American                 54   54            54  \n",
       "Hispanic/Latino                       146  147           147  \n",
       "White/Caucasian                        83   83            83  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = join_data_df.groupby('ethnicity').count()\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(389/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cand_id</th>\n",
       "      <th>name</th>\n",
       "      <th>proficiency</th>\n",
       "      <th>language_code</th>\n",
       "      <th>Predict_eth</th>\n",
       "      <th>candidate_name</th>\n",
       "      <th>candidate_surname</th>\n",
       "      <th>candidate_country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>url</th>\n",
       "      <th>candidate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>English</td>\n",
       "      <td>NATIVE_OR_BILINGUAL</td>\n",
       "      <td>en</td>\n",
       "      <td>White/Caucasian</td>\n",
       "      <td>Saurabh</td>\n",
       "      <td>Singhal</td>\n",
       "      <td>US</td>\n",
       "      <td>Asian</td>\n",
       "      <td>https://www.linkedin.com/in/saurabh-singhal-b8...</td>\n",
       "      <td>125201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>NATIVE_OR_BILINGUAL</td>\n",
       "      <td>vi</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>Le</td>\n",
       "      <td>US</td>\n",
       "      <td>Asian</td>\n",
       "      <td>https://www.linkedin.com/in/nguyenle89</td>\n",
       "      <td>159427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>NATIVE_OR_BILINGUAL</td>\n",
       "      <td>ml</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Shamjith</td>\n",
       "      <td>antholi</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>https://www.linkedin.com/in/shamjith-antholi-a...</td>\n",
       "      <td>7366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>English</td>\n",
       "      <td>NATIVE_OR_BILINGUAL</td>\n",
       "      <td>en</td>\n",
       "      <td>White/Caucasian</td>\n",
       "      <td>Philippe</td>\n",
       "      <td>Thanadabouth</td>\n",
       "      <td>FR</td>\n",
       "      <td>Asian</td>\n",
       "      <td>https://www.linkedin.com/in/philippethanadabou...</td>\n",
       "      <td>15612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NATIVE_OR_BILINGUAL</td>\n",
       "      <td>zh</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Dong</td>\n",
       "      <td>Jiang</td>\n",
       "      <td>US</td>\n",
       "      <td>Asian</td>\n",
       "      <td>https://www.linkedin.com/in/djstudio?authType=...</td>\n",
       "      <td>122889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cand_id        name          proficiency language_code      Predict_eth  \\\n",
       "0       10     English  NATIVE_OR_BILINGUAL            en  White/Caucasian   \n",
       "1       11  Vietnamese  NATIVE_OR_BILINGUAL            vi            Asian   \n",
       "2       13   Malayalam  NATIVE_OR_BILINGUAL            ml            Asian   \n",
       "3       15     English  NATIVE_OR_BILINGUAL            en  White/Caucasian   \n",
       "4       16     Chinese  NATIVE_OR_BILINGUAL            zh            Asian   \n",
       "\n",
       "  candidate_name candidate_surname candidate_country ethnicity  \\\n",
       "0        Saurabh           Singhal                US     Asian   \n",
       "1         Nguyen                Le                US     Asian   \n",
       "2       Shamjith           antholi                CA     Asian   \n",
       "3       Philippe      Thanadabouth                FR     Asian   \n",
       "4           Dong             Jiang                US     Asian   \n",
       "\n",
       "                                                 url  candidate_id  \n",
       "0  https://www.linkedin.com/in/saurabh-singhal-b8...        125201  \n",
       "1             https://www.linkedin.com/in/nguyenle89        159427  \n",
       "2  https://www.linkedin.com/in/shamjith-antholi-a...          7366  \n",
       "3  https://www.linkedin.com/in/philippethanadabou...         15612  \n",
       "4  https://www.linkedin.com/in/djstudio?authType=...        122889  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join_data_df.drop_duplicates(subset=['candidate_id','language_code'], keep=False)\n",
    "join_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_data_df.to_csv('join_data_newdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unknown result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data_df_notNAN = join_data_df.loc[join_data_df['Predict_eth']!='UNKNOWN']\n",
    "len(join_data_df_notNAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw result - include english, france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Asian       0.81      0.83      0.82        94\n",
      "Black/African American       0.62      0.26      0.37        50\n",
      "       Hispanic/Latino       0.90      0.69      0.78       133\n",
      "     Other/Multiracial       0.00      0.00      0.00         0\n",
      "       White/Caucasian       0.47      0.82      0.60        78\n",
      "\n",
      "           avg / total       0.74      0.70      0.69       355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(join_data_df_notNAN['ethnicity'],join_data_df_notNAN['Predict_eth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black/African American</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Other/Multiracial</th>\n",
       "      <th>White/Caucasian</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               Asian  Black/African American  Hispanic/Latino  \\\n",
       "Actual                                                                   \n",
       "Asian                      78                       1                1   \n",
       "Black/African American     10                      13                3   \n",
       "Hispanic/Latino             5                       3               92   \n",
       "White/Caucasian             3                       4                6   \n",
       "All                        96                      21              102   \n",
       "\n",
       "Predicted               Other/Multiracial  White/Caucasian  All  \n",
       "Actual                                                           \n",
       "Asian                                   0               14   94  \n",
       "Black/African American                  0               24   50  \n",
       "Hispanic/Latino                         0               33  133  \n",
       "White/Caucasian                         1               64   78  \n",
       "All                                     1              135  355  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(join_data_df_notNAN['ethnicity'],join_data_df_notNAN['Predict_eth'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw result - include france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data_df_notEng = join_data_df_notNAN.loc[join_data_df_notNAN['language_code']!='en']\n",
    "len(join_data_df_notEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Asian       0.81      0.96      0.88        81\n",
      "Black/African American       0.62      0.48      0.54        27\n",
      "       Hispanic/Latino       0.90      0.81      0.86       113\n",
      "     Other/Multiracial       0.00      0.00      0.00         0\n",
      "       White/Caucasian       0.67      0.68      0.67        44\n",
      "\n",
      "           avg / total       0.81      0.80      0.80       265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(join_data_df_notEng['ethnicity'],join_data_df_notEng['Predict_eth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black/African American</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Other/Multiracial</th>\n",
       "      <th>White/Caucasian</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               Asian  Black/African American  Hispanic/Latino  \\\n",
       "Actual                                                                   \n",
       "Asian                      78                       1                1   \n",
       "Black/African American     10                      13                3   \n",
       "Hispanic/Latino             5                       3               92   \n",
       "White/Caucasian             3                       4                6   \n",
       "All                        96                      21              102   \n",
       "\n",
       "Predicted               Other/Multiracial  White/Caucasian  All  \n",
       "Actual                                                           \n",
       "Asian                                   0                1   81  \n",
       "Black/African American                  0                1   27  \n",
       "Hispanic/Latino                         0               13  113  \n",
       "White/Caucasian                         1               30   44  \n",
       "All                                     1               45  265  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_notEng = pd.crosstab(join_data_df_notEng['ethnicity'],join_data_df_notEng['Predict_eth'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion_notEng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw result - remove english and france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_data_df_notEngFrn = join_data_df_notEng.loc[join_data_df_notEng['language_code']!='fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Asian       0.81      0.97      0.89        80\n",
      "Black/African American       0.92      0.44      0.59        25\n",
      "       Hispanic/Latino       0.90      0.84      0.87       110\n",
      "     Other/Multiracial       0.00      0.00      0.00         0\n",
      "       White/Caucasian       0.67      0.73      0.70        41\n",
      "\n",
      "           avg / total       0.84      0.82      0.82       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(join_data_df_notEngFrn['ethnicity'],join_data_df_notEngFrn['Predict_eth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black/African American</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Other/Multiracial</th>\n",
       "      <th>White/Caucasian</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               Asian  Black/African American  Hispanic/Latino  \\\n",
       "Actual                                                                   \n",
       "Asian                      78                       0                1   \n",
       "Black/African American     10                      11                3   \n",
       "Hispanic/Latino             5                       0               92   \n",
       "White/Caucasian             3                       1                6   \n",
       "All                        96                      12              102   \n",
       "\n",
       "Predicted               Other/Multiracial  White/Caucasian  All  \n",
       "Actual                                                           \n",
       "Asian                                   0                1   80  \n",
       "Black/African American                  0                1   25  \n",
       "Hispanic/Latino                         0               13  110  \n",
       "White/Caucasian                         1               30   41  \n",
       "All                                     1               45  256  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_notEng = pd.crosstab(join_data_df_notEngFrn['ethnicity'],join_data_df_notEngFrn['Predict_eth'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion_notEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425201171185 0.328980405197 0.32625200568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics.classification.classification_report>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = np.mean(metrics.precision_recall_fscore_support(join_df['ethnicity'], join_df['Predict_eth'])[0])\n",
    "recall = np.mean(metrics.precision_recall_fscore_support(join_df['ethnicity'], join_df['Predict_eth'])[1])\n",
    "fscore = np.mean(metrics.precision_recall_fscore_support(join_df['ethnicity'], join_df['Predict_eth'])[2])\n",
    "print(precision,recall,fscore)\n",
    "metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black/African American</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Other/Multiracial</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>White/Caucasian</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>150</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               Asian  Black/African American  Hispanic/Latino  \\\n",
       "Actual                                                                   \n",
       "Asian                      55                       0                1   \n",
       "Black/African American      7                       5                3   \n",
       "Hispanic/Latino             5                       3               56   \n",
       "White/Caucasian             4                       2                2   \n",
       "All                        71                      10               62   \n",
       "\n",
       "Predicted               Other/Multiracial  UNKNOWN  White/Caucasian  All  \n",
       "Actual                                                                    \n",
       "Asian                                   0       15               25   96  \n",
       "Black/African American                  0        6               19   40  \n",
       "Hispanic/Latino                         0       17               50  131  \n",
       "White/Caucasian                         1        1               56   66  \n",
       "All                                     1       39              150  333  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(join_df['ethnicity'], join_df['Predict_eth'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_data_df_notEngFrArb = join_data_df_notEng.loc[join_data_df_notEng['language_code']!='ar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Asian       0.81      0.96      0.88        81\n",
      "Black/African American       0.63      0.46      0.53        26\n",
      "       Hispanic/Latino       0.90      0.81      0.86       113\n",
      "     Other/Multiracial       0.00      0.00      0.00         0\n",
      "       White/Caucasian       0.67      0.70      0.68        43\n",
      "\n",
      "           avg / total       0.81      0.81      0.80       263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(join_data_df_notEngFrArb['ethnicity'],join_data_df_notEngFrArb['Predict_eth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black/African American</th>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <th>Other/Multiracial</th>\n",
       "      <th>White/Caucasian</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/African American</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasian</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               Asian  Black/African American  Hispanic/Latino  \\\n",
       "Actual                                                                   \n",
       "Asian                      78                       1                1   \n",
       "Black/African American     10                      12                3   \n",
       "Hispanic/Latino             5                       3               92   \n",
       "White/Caucasian             3                       3                6   \n",
       "All                        96                      19              102   \n",
       "\n",
       "Predicted               Other/Multiracial  White/Caucasian  All  \n",
       "Actual                                                           \n",
       "Asian                                   0                1   81  \n",
       "Black/African American                  0                1   26  \n",
       "Hispanic/Latino                         0               13  113  \n",
       "White/Caucasian                         1               30   43  \n",
       "All                                     1               45  263  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_notEng = pd.crosstab(join_data_df_notEngFrArb['ethnicity'],join_data_df_notEngFrArb['Predict_eth'], rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion_notEng"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
